%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{cite}

\title{\LARGE \bf
One Eye Leads the Blind: Asymmetric Multi-Robot Navigation with Visual Guidance
}


\author{Albert Author$^{1}$ and Bernard D. Researcher$^{2}$% <-this % stops a space
\thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$Albert Author is with Faculty of Electrical Engineering, Mathematics and Computer Science,
        University of Twente, 7500 AE Enschede, The Netherlands
        {\tt\small albert.author@papercept.net}}%
\thanks{$^{2}$Bernard D. Researcheris with the Department of Electrical Engineering, Wright State University,
        Dayton, OH 45435, USA
        {\tt\small b.d.researcher@ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
In field operations where robots are exposed to extreme environments, the risk of sensor failure is a reality that affects the performance of robots and the ultimate success of their operation. This paper investigates the challenge of Asymmetric Multi-Robot Navigation, addressing a scenario where a sensing-rich "Leader" robot must guide a sensor-less "Follower" robot through an unknown environment.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Unmanned robotic systems are progressively being deployed in hazardous 
environments, including reconnaissance, search and rescue, and 
disaster response, where human presence is dangerous or not feasible~\cite{wang2025multi}. 
However, these missions often occur under harsh conditions that accelerate sensor degradation: dust and debris occlude cameras, electromagnetic interference disrupts lidar, and physical impacts could damage the perception hardware~\cite{ebadi2022present}. When a robot's sensors fail mid-mission in remote or inaccessible locations (e.g., underground tunnels, disaster sites, or enemy territory), the most likely response is to abort the mission and abandon the robot, resulting in costly equipment loss and incomplete objectives. This raises the question of whether a functional teammate can actively guide a sensor-impaired robot to safety or mission completion rather than abandoning it.

Asymmetric coordination strategies in multi-robot systems have been proposed to address mismatched capabilities among teammates. One approach uses a fixed sensor infrastructure that performs perception and localization on the robots' behalf, enabling effective navigation and coordination despite limited onboard sensing. This approach may not work in situations where setting up a fixed sensor infrastructure in the environment is not possible. For example, in dangerous environments that are being explored for the first time, it may be infeasible to set up such infrastructure.

Another approach is the leader–follower paradigm, in which a sensor-rich leader with privileged information computes safe trajectories while follower robots track and maintain formation along the leader’s path~\cite{petrinic2013leader}. However, this approach typically assumes that followers retain at least minimal sensing~\cite{wang2019vision} to track the leader or localize within the environment, an assumption that breaks down when a follower’s sensors have completely failed. This gap motivates the need for recovery mechanisms that remain effective even when a robot's perception sensor has failed.

Importantly, asymmetric navigation is not unique to robotic systems. For example, in complex, crowded, or unfamiliar environments, a blind person is often guided by a sighted companion who has privileged information about the environment, plans safe navigation trajectories, and communicates them through physical contact and voice, allowing safe movement while relying entirely on the guide. A similar idea appears in human–robot interaction, where robotic guide dogs with visual perception assist blind humans~\cite{hwang2025guidenav}. Inspired by these examples, we ask if a visually capable robot can guide another robot that has no perception at all, enabling safe navigation purely through its own sensing, localization and motion-based communication.

To address the challenges of asymmetric navigation under partial observability, we adopt a two-phase reinforcement learning framework based on privileged knowledge distillation. In Phase 1, we train a teacher policy in simulation using reinforcement learning with access to full ground-truth environment states, enabling the policy to learn robust navigation strategies with complete situational awareness. In Phase 2, we distill this expertise into a student policy that operates using only onboard sensing and limited observations. The student is trained via supervised imitation to replicate the teacher’s actions, thereby transferring privileged knowledge without requiring full state access at deployment. This simulation-to-reality pipeline enables strong generalization to unseen environments. 

We validate our approach through real-world deployment on two Hiwonder Orin robots, where a vision-less follower successfully navigates cluttered environments by executing movement commands communicated by a privileged leader.

The key contributions of this paper are as follows:

\begin{itemize}
    \item First item 
    We introduce a novel asymmetric navigation framework in which a vision-enabled robot guides a vision-less robot through cluttered environments via communicated motion commands.
    
    \item We extend reinforcement learning with privileged knowledge distillation to the asymmetric multi-robot setting, enabling a follower robot to operate under partial observability while leveraging a leader’s privileged perception.
    
    \item We demonstrate successful real-world generalization through deployment on physical robots, validating robust navigation performance across diverse cluttered environments.

    
\end{itemize}









% Multi-robot systems have become very useful in domains such as autonomous logistics, search and rescue, and exploration of unknown environments~\cite{wang2025multi}. These systems provide significant benefits in terms of operational efficiency, parallel area coverage and redundancy. Cooperation in these systems can be achieved through various control strategies, ranging from fully centralized approaches, where sensing, computation, and communication are handled by a single supervisory unit, to fully decentralized methods, where each robot operates independently~\cite{farivarnejad2022multirobot}. 

% Behavior-based approach

% Virtual Structure Approach

% These systems commonly utilize the leader-follower framework, where one or more leader robots with enhanced capabilities coordinate a team of follower robots. An advantage of this technique is that follower robots do not need to perform the most computation in terms of determining the goal, however, existing leader-follower approaches typically assume that follower robots maintain sufficient sensing and localization capabilities for independent navigation and obstacle avoidance~\cite{...}. This assumption necessitates that the followers have capable sensor suites, whereas in real-world deployments, this requirement could be a challenge as robots often face heterogeneous constraints due to budget limitations, payload restrictions, or hardware failures especially when exploring dangerous or very risky environments~\cite{...}.

% Unlike traditional leader-follower setups where followers track a leader using their own onboard LiDAR or cameras, we explore a scenario where a mobile leader with vision must guide a follower that lacks all exteroceptor sensors. This setup is highly relevant for minimizing system costs and providing redundancy in the event of sensor failure. The primary challenge lies in the tight coupling required between the leader’s path planning and the relative state of the follower, especially when navigating complex obstacle courses where the leader must "think" for both entities.


\section{RELATED WORKS}

\subsection{Heading 
2}

Navigation of a sensorless agent via external sensing is validated by recent research demonstrating that autonomous navigation does not strictly require onboard exteroceptive sensors if external intelligence is available. (...Verma and Savkin) present a dynamic programming-based algorithm that enables a sensorless mobile robot to navigate dynamic environments using a fixed external sensor network. Their approach offloads localization, obstacle tracking, and path planning entirely to fixed infrastructure (LiDARs), proving that a robot can react to dynamic obstacles without onboard perception [1]. The methodology of transfering navigational competency from a knowledgeable agent to a sensor-limited agent is explored through "Teacher-Student" and "Teach-and-Repeat" paradigms. (Qu et al) utilize a two-stage training process for low-cost hexapods where a "Teacher" policy, trained with privileged information (height maps and joint feedback), distills knowledge into a "Student" policy that relies on limited onboard sensors.
Furthermore, the concept of asymmetric guidance is strongly represented in Human-Robot Interaction (HRI) for the visually impaired. Hwang et al [3]. developed "GuideNav," a robotic guide dog system that uses visual teach-and-repeat methods to guide blind humans. Their success in kilometer-scale guidance without LiDAR suggests that vision-based topological maps are a viable low-bandwidth mechanism for linking Leaders and Followers.
Robust Perception Capabilities for the Leader Agent For an asymmetric system to function, the "Leader" must possess high-fidelity robustness to compensate for the "Blind" followers. Recent literature establishes the necessary capabilities for such a leader.
Agility and Safety: He et al [4]. propose the "Agile But Safe" (ABS) framework, which employs a dual-policy setup (agile vs. recovery) governed by reach-avoid values. Hoeller et al [5] demonstrate that learning a belief state representation from depth images allows a robot to handle partial observability and dynamic obstacles. This memory-based representation is crucial for a Leader robot to predict environmental changes that might endanger the sensorless Follower. To ensure the Leader works in the "unknown environments", Yu et al.~\cite{yu2025depth} introduce domain adaptation techniques to align simulated depth features with real-world inputs. This ensures the Leader's perception remains reliable when transferring from training simulations to physical deployment [6].

\subsection{Maintaining the Integrity of the Specifications}

The template is used to format your paper and style the text. All margins, column widths, line spaces, and text fonts are prescribed; please do not alter them. You may note peculiarities. For example, the head margin in this template measures proportionately more than is customary. This measurement and others are deliberate, using specifications that anticipate your paper as one part of the entire proceedings, and not as an independent document. Please do not revise any of the current designations

\section{Problem Formulation}

Markov Decision Process

Finally, complete content and organizational editing before formatting. Please take note of the following items when proofreading spelling and grammar:

\subsection{Abbreviations and Acronyms} Define abbreviations and acronyms the first time they are used in the text, even after they have been defined in the abstract. Abbreviations such as IEEE, SI, MKS, CGS, sc, dc, and rms do not have to be defined. Do not use abbreviations in the title or heads unless they are unavoidable.

\subsection{Units}

\begin{itemize}

\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as Ò3.5-inch disk driveÓ.
\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
\item Do not mix complete spellings and abbreviations of units: ÒWb/m2Ó or Òwebers per square meterÓ, not Òwebers/m2Ó.  Spell out units when they appear in text: Ò. . . a few henriesÓ, not Ò. . . a few HÓ.
\item Use a zero before decimal points: Ò0.25Ó, not Ò.25Ó. Use Òcm3Ó, not ÒccÓ. (bullet list)

\end{itemize}


\subsection{Equations}

The equations are an exception to the prescribed specifications of this template. You will need to determine whether or not your equation should be typed using either the Times New Roman or the Symbol font (please no other font). To create multileveled equations, it may be necessary to treat the equation as a graphic and insert it into the text after your paper is styled. Number equations consecutively. Equation numbers, within parentheses, are to position flush right, as in (1), using a right tab stop. To make your equations more compact, you may use the solidus ( / ), the exp function, or appropriate exponents. Italicize Roman symbols for quantities and variables, but not Greek symbols. Use a long dash rather than a hyphen for a minus sign. Punctuate equations with commas or periods when they are part of a sentence, as in

$$
\alpha + \beta = \chi \eqno{(1)}
$$

Note that the equation is centered using a center tab stop. Be sure that the symbols in your equation have been defined before or immediately following the equation. Use Ò(1)Ó, not ÒEq. (1)Ó or Òequation (1)Ó, except at the beginning of a sentence: ÒEquation (1) is . . .Ó

\subsection{Some Common Mistakes}
\begin{itemize}


\item The word ÒdataÓ is plural, not singular.
\item The subscript for the permeability of vacuum ?0, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ÒoÓ.
\item In American English, commas, semi-/colons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ÒinsetÓ, not an ÒinsertÓ. The word alternatively is preferred to the word ÒalternatelyÓ (unless you really mean something that alternates).
\item Do not use the word ÒessentiallyÓ to mean ÒapproximatelyÓ or ÒeffectivelyÓ.
\item In your paper title, if the words Òthat usesÓ can accurately replace the word ÒusingÓ, capitalize the ÒuÓ; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ÒaffectÓ and ÒeffectÓ, ÒcomplementÓ and ÒcomplimentÓ, ÒdiscreetÓ and ÒdiscreteÓ, ÒprincipalÓ and ÒprincipleÓ.
\item Do not confuse ÒimplyÓ and ÒinferÓ.
\item The prefix ÒnonÓ is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ÒetÓ in the Latin abbreviation Òet al.Ó.
\item The abbreviation Òi.e.Ó means Òthat isÓ, and the abbreviation Òe.g.Ó means Òfor exampleÓ.

\end{itemize}


\section{EXPERIMENTS}

Use this sample document as your LaTeX source file to create your document. Save this file as {\bf root.tex}. You have to make sure to use the cls file that came with this distribution. If you use a different style file, you cannot expect to get required margins. Note also that when you are creating your out PDF file, the source file is only part of the equation. {\it Your \TeX\ $\rightarrow$ PDF filter determines the output file size. Even if you make all the specifications to output a letter file in the source - if your filter is set to produce A4, you will only get A4 output. }

It is impossible to account for all possible situation, one would encounter using \TeX. If you are using multiple \TeX\ files you must make sure that the ``MAIN`` source file is called root.tex - this is particularly important if your conference is using PaperPlaza's built in \TeX\ to PDF conversion tool.

\subsection{Headings, etc}

Text heads organize the topics on a relational, hierarchical basis. For example, the paper title is the primary text head because all subsequent material relates and elaborates on this one topic. If there are two or more sub-topics, the next level head (uppercase Roman numerals) should be used and, conversely, if there are not at least two sub-topics, then no subheads should be introduced. Styles named ÒHeading 1Ó, ÒHeading 2Ó, ÒHeading 3Ó, and ÒHeading 4Ó are prescribed.

\subsection{Figures and Tables}

Positioning Figures and Tables: Place figures and tables at the top and bottom of columns. Avoid placing them in the middle of columns. Large figures and tables may span across both columns. Figure captions should be below the figures; table heads should appear above the tables. Insert figures and tables after they are cited in the text. Use the abbreviation ÒFig. 1Ó, even at the beginning of a sentence.

\begin{table}[h]
\caption{An Example of a Table}
\label{table_example}
\begin{center}
\begin{tabular}{|c||c|}
\hline
One & Two\\
\hline
Three & Four\\
\hline
\end{tabular}
\end{center}
\end{table}


   \begin{figure}[thpb]
      \centering
      \framebox{\parbox{3in}{We suggest that you use a text box to insert a graphic (which is ideally a 300 dpi TIFF or EPS file, with all fonts embedded) because, in an document, this method is somewhat more stable than directly inserting a picture.
}}
      %\includegraphics[scale=1.0]{figurefile}
      \caption{Inductance of oscillation winding on amorphous
       magnetic core versus DC bias magnetic field}
      \label{figurelabel}
   \end{figure}
   

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words rather than symbols or abbreviations when writing Figure axis labels to avoid confusing the reader. As an example, write the quantity ÒMagnetizationÓ, or ÒMagnetization, MÓ, not just ÒMÓ. If including units in the label, present them within parentheses. Do not label axes only with units. In the example, write ÒMagnetization (A/m)Ó or ÒMagnetization {A[m(1)]}Ó, not just ÒA/mÓ. Do not label axes with a ratio of quantities and units. For example, write ÒTemperature (K)Ó, not ÒTemperature/K.Ó

\section{CONCLUSIONS}

A conclusion section is not required. Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance of the work or suggest applications and extensions. 

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}

Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}

The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

References are important to the reader; therefore, each citation must be complete and correct. If at all possible, references should be commonly available publications.


\bibliographystyle{ieeetr}
\bibliography{references}
% \begin{thebibliography}{99}

% \bibitem{c1} S. C. Verma and A. V. Savkin, “Navigation of a sensorless autonomous mobile robot in unknown dynamic environments by an external sensor network,” in Proc. IEEE, 2025.
% \bibitem{c2} T. Qu, D. Li, A. Zakhor, W. Yu, and T. Zhang, “Versatile locomotion skills for hexapod robots,” arXiv preprint arXiv:2412.10628, 2024.
% \bibitem{c3} H. Hwang et al., “GuideNav: User-informed development of a vision-only robotic navigation assistant for blind travelers,” in Proc. ACM/IEEE Int. Conf. Human-Robot Interaction (HRI), Edinburgh, UK, 2026.

% \bibitem{c4} T. He, C. Zhang, W. Xiao, G. He, C. Liu, and G. Shi, “Agile but safe: Learning collision-free high-speed legged locomotion,” arXiv preprint arXiv:2401.17583, 2024.
% \bibitem{c5} D. Hoeller, L. Wellhausen, F. Farshidian, and M. Hutter, “Learning a state representation and navigation in cluttered and dynamic environments,” IEEE Robot. Autom. Lett., 2021.
% \bibitem{c6}  H. Yu, C. De Wagter, and G. C. H. E. de Croon, “Depth transfer: Learning to see like a simulator for real-world drone navigation,” arXiv preprint arXiv:2505.12428, 2025.
% \bibitem{c7} 
% \bibitem{c8} 
% \bibitem{c9} 
% \bibitem{c10}





% \end{thebibliography}




\end{document}
